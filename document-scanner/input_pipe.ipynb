{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "%matplotlib inline\n",
    "\n",
    "from pyimagesearch.transform import four_point_transform, order_points\n",
    "from pyimagesearch import imutils\n",
    "from input_utils import showImg, get_images, crop, expand_rect\n",
    "import numpy as np\n",
    "from PIL import Image as Pim\n",
    "from PIL import ImageOps\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## helpers, expand_rect, get_images, crop\n",
    "\n",
    "def make_rect(center, dist):\n",
    "    rect = np.array([center, center, center, center])\n",
    "    dist = int(dist/2)\n",
    "    rect[0]    -= dist\n",
    "    rect[1][0] += dist\n",
    "    rect[1][1] -= dist\n",
    "    rect[2]    += dist\n",
    "    rect[3][0] -= dist\n",
    "    rect[3][1] += dist\n",
    "    return rect\n",
    "\n",
    "# takes 4 pt rect, goes over each corner and expands sub rect\n",
    "def center_rect(rect, dim):\n",
    "    dist = int((rect[1][0] - rect[0][0])/ (dim - 1))\n",
    "    rect = expand_rect(int(dist/2))\n",
    "    slices = []\n",
    "    for x in range(dim):\n",
    "        for y in range(dim):\n",
    "            center = rect\n",
    "            expand_rect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     27,
     71,
     108
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_for_blue(frame):\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([135,255,255])\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    new_mask = cv2.GaussianBlur(mask, (9, 9),3)\n",
    "    new_mask = cv2.inRange(new_mask, 200, 255)\n",
    "\n",
    "    \n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    #cv2.imshow('frame',frame)\n",
    "    #cv2.imshow('mask',mask)\n",
    "    #cv2.imshow('res',res)\n",
    "    #k = cv2.waitKey(50) & 0xFF \n",
    "    #if k == 27:\n",
    "    #    cv2.destroyAllWindows()\n",
    "    #    cv2.waitKey(1)\n",
    "    #cv2.waitKey(1)\n",
    "    return res, new_mask\n",
    "\n",
    "def blob_detector_ex (img):\n",
    "\n",
    "    # Read image\n",
    "    #im = cv2.imread(\"blob.jpg\")\n",
    "    im = img\n",
    "    im = cv2.GaussianBlur(im, (3, 3),1)\n",
    "    \n",
    "    # Set up the SimpleBlobdetector with default parameters.\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "     \n",
    "    # Change thresholds\n",
    "    params.minThreshold = 100;\n",
    "    params.maxThreshold = 256;\n",
    "     \n",
    "    # Filter by Area.\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 50\n",
    "     \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = False\n",
    "    params.minCircularity = 0.1\n",
    "     \n",
    "    # Filter by Convexity\n",
    "    params.filterByConvexity = False\n",
    "    #params.minConvexity = 0.5\n",
    "     \n",
    "    # Filter by Inertia\n",
    "    params.filterByInertia =False\n",
    "    params.minInertiaRatio = 0.5\n",
    "    \n",
    "    # Set up the detector with set parameters.\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "     \n",
    "    # Detect blobs.\n",
    "    reversemask = 255 - im\n",
    "    keypoints = detector.detect(reversemask)\n",
    "     \n",
    "    # Draw detected blobs as red circles.\n",
    "    # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "    im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), \n",
    "                                           cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    return keypoints, im_with_keypoints\n",
    "\n",
    "def snapshots():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"test\")\n",
    "    img_counter = len(listdir('frames'))\n",
    "    \n",
    "    images = []\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        cv2.imshow(\"test\", frame)\n",
    "        if not ret:\n",
    "            break\n",
    "        k = cv2.waitKey(1)\n",
    "    \n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            \n",
    "            break\n",
    "            \n",
    "        elif k%256 == 32:\n",
    "            # SPACE pressed\n",
    "            img_name = \"frames/{}.png\".format(img_counter)\n",
    "            \n",
    "            \n",
    "            #cv2.putText(\"test\", text, (0,0), fontFace, fontScale, thickness)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            images.append(frame)\n",
    "            \n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "    \n",
    "    cam.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    return images\n",
    "\n",
    "def pipeline(images, dim=6):\n",
    "    rects = []\n",
    "    imgs = []\n",
    "    for frame in images:\n",
    "        res, mask = mask_for_blue(frame)\n",
    "        \n",
    "        #get pnts\n",
    "        keypoints, im_with_keypoints = blob_detector_ex(mask)\n",
    "        pt_list = [keypoint.pt for keypoint in keypoints]\n",
    "        pts = np.asarray(pt_list)\n",
    "        \n",
    "        # perfrom scanner transform\n",
    "        warped = four_point_transform(frame,pts,True)\n",
    "        \n",
    "        # crop\n",
    "        cropped = warped\n",
    "        #cropped = crop(warped, 13, 15, 12, 12)\n",
    "        \n",
    "        # get closer contour\n",
    "        gray = cv2.cvtColor(cropped,cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.inRange(gray, 105, 255)\n",
    "        \n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        erosion = cv2.erode(gray,kernel,iterations = 1)\n",
    "        gray = cv2.GaussianBlur(erosion, (5, 5),0)\n",
    "        \n",
    "        im2, contours, hierarchy = cv2.findContours(gray.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = sorted(contours, key = cv2.contourArea, reverse = True)[:5]\n",
    "        \n",
    "        c = cnts[1]\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.10 * peri, True)\n",
    "            \n",
    "        im_cnts2 = cropped.copy()\n",
    "        blah2 = cv2.drawContours(im_cnts2, [approx], -1, (0,255,0), 3)\n",
    "        showImg(blah2)\n",
    "        \n",
    "        approx.resize(4,2)\n",
    "        rect = order_points(approx) # UL, UR, BR, BL\n",
    "        dist = int((rect[1][0] - rect[0][0])/ (dim - 1))\n",
    "        rect = expand_rect(int(dist/2), rect)\n",
    "        warped_gray = four_point_transform(gray,rect,True)\n",
    "        warped_color = four_point_transform(cropped,rect,True)\n",
    "        \n",
    "        #showImg(warped_gray, 3, cv2.COLOR_GRAY2RGB)\n",
    "        showImg(warped_color, 3)\n",
    "        imgs.append(warped_color)\n",
    "        rects.append(rect)\n",
    "    return rects, imgs\n",
    "\n",
    "def splitPieces(arr, index=0):\n",
    "    im = Pim.fromarray(arr)\n",
    "    \n",
    "    #im = PImage.open(warped_gray)\n",
    "    dist = int(im.size[0]/dim)\n",
    "    pad = int(dist/4) \n",
    "    \n",
    "    im = ImageOps.expand(im,50, (200,200,200))\n",
    "    #im.show()\n",
    "    crops = np.empty([dim,dim],dtype=Pim.Image)\n",
    "    for x in range(dim):\n",
    "        for y in range(dim):\n",
    "            area = x*dist-pad+50, y*dist-pad+50, x*dist + pad+dist+50, y*dist +pad+50+dist\n",
    "            crops[x][y] = im.crop(area)\n",
    "            crops[x][y] = crops[x][y].resize((151, 151), Pim.ANTIALIAS)\n",
    "            #crops[x][y].show()\n",
    "            #showImg(np.asarray(crops[x][y]), 2)\n",
    "            crops[x][y].save('goTiles/' + str(index) +'-('+str(x)+','+str(y)+').png')\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_images('./frames', stack=False)\n",
    "#for image in images:\n",
    "#    showImg(image, 3)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = snapshots()\n",
    "for image in images:\n",
    "    showImg(image, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 6\n",
    "rects, imgs = pipeline(images, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline of flow:\n",
    "    setup camera\n",
    "    take image\n",
    "    identify blob coords\n",
    "    pass coords to transform\n",
    "    refine image \n",
    "        - \n",
    "    divide image into 13x13 (or 9x9, etc)\n",
    "    determine if center is black, white or cross\n",
    "    make matrix of -1,0,1 for black, none, white piece\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "bigcrops = []\n",
    "for img in imgs:\n",
    "    bigcrops.append(splitPieces(img,i))\n",
    "    i += 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     20,
     30,
     40
    ]
   },
   "outputs": [],
   "source": [
    "### create y labels\n",
    "# 1 black, 2 none, 3 white\n",
    "#showImg(imgs[0],1)\n",
    "#showImg(np.asarray(crops[1,2])) # looks good for indexing ! \n",
    "# img3key = np.asarray([[2,2,2,2,2,2],  ALL 2's example\n",
    "#                      [2,2,2,2,2,2],\n",
    "#                      [2,2,2,2,2,2],\n",
    "#                      [2,2,2,2,2,2],\n",
    "#                      [2,2,2,2,2,2],\n",
    "#                      [2,2,2,2,2,2]])\n",
    "img0key = np.asarray([[2,2,2,2,2,2],\n",
    "                      [2,2,2,2,2,2],\n",
    "                      [2,3,1,2,1,2],\n",
    "                      [2,1,3,1,2,2],\n",
    "                      [2,2,3,2,3,2],\n",
    "                      [2,2,2,2,2,2]])\n",
    "print('img0key mean:',img0key.mean())\n",
    "img0key.resize(36,)\n",
    "\n",
    "#showImg(imgs[1])\n",
    "img1key = np.asarray([[2,2,2,2,2,2],\n",
    "                      [2,2,2,2,2,2],\n",
    "                      [2,3,1,1,1,2],\n",
    "                      [2,1,2,3,2,2],\n",
    "                      [2,2,3,2,3,2],\n",
    "                      [2,2,2,2,2,2]])\n",
    "print('img1key mean:',img1key.mean()) # 4 and 4 black, so should average to none, ie number 2\n",
    "img1key.resize(36,)\n",
    "\n",
    "#showImg(imgs[2])\n",
    "img2key = np.asarray([[2,2,2,2,2,2],\n",
    "                      [2,1,2,3,2,2],\n",
    "                      [2,1,2,2,1,2],\n",
    "                      [2,1,3,3,2,2],\n",
    "                      [2,2,2,2,3,2],\n",
    "                      [2,2,2,2,2,2]])\n",
    "img2key.resize(36,)\n",
    "print('img2key mean:',img2key.mean()) # 4 and 4 black, so should average to none, ie number 2\n",
    "\n",
    "#showImg(imgs[3])\n",
    "img3key = np.asarray([[2,2,2,2,2,2],\n",
    "                      [1,2,2,1,2,2],\n",
    "                      [1,2,3,3,2,2],\n",
    "                      [2,3,2,2,2,2],\n",
    "                      [2,1,2,2,3,2],\n",
    "                      [2,2,2,2,2,2]])\n",
    "img3key.resize(36,)\n",
    "print('img3key mean:',img3key.mean()) # 4 and 4 black, so should average to none, ie number 2\n",
    "\n",
    "key = np.concatenate([img0key,img1key,img2key,img3key])\n",
    "print(\"key.shape =\",key.shape)\n",
    "np.savetxt(\"key.csv\", key, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = np.genfromtxt('key.csv', delimiter=',')\n",
    "print(\"key.shape =\",key.shape)\n",
    "print('key.mean:',key.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_key = np.asarray(key)\n",
    "print(key[0])\n",
    "print(type(key[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "tiles = get_images('./goTiles')\n",
    "#print(len(tiles))\n",
    "showImg(tiles[130])\n",
    "#print(tiles[0].shape)\n",
    "\n",
    "X = np.stack(tiles)\n",
    "# beware images of wrong dim hiding in folder...\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from GoScanner.py\n",
    "# USAGE\n",
    "# python goScanner.py --image images/page.jpg\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.transform import four_point_transform\n",
    "from pyimagesearch import imutils\n",
    "from skimage.filters import threshold_adaptive\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# load the image and compute the ratio of the old height\n",
    "# to the new height, clone it, and resize it\n",
    "image = cv2.imread(args[\"image\"])\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    "\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "#edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "# show the original image and the edge detected image\n",
    "#print (\"STEP 1: Edge Detection\")\n",
    "#cv2.imshow(\"Image\", image)\n",
    "#cv2.imshow(\"Edged\", edged)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "#_2, cnts, _ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# loop over the contours\n",
    "#for c in cnts:\n",
    "#\t# approximate the contour\n",
    "#\tperi = cv2.arcLength(c, True)\n",
    "#\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "#\n",
    "#\t# if our approximated contour has four points, then we\n",
    "#\t# can assume that we have found our screen\n",
    "#\tif len(approx) == 4:\n",
    "#\t\tscreenCnt = approx\n",
    "#\t\tbreak\n",
    "\n",
    "# show the contour (outline) of the piece of paper\n",
    "#print (\"STEP 2: Find contours of paper\")\n",
    "#cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "#cv2.imshow(\"Outline\", image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "#warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "#warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "#warped = threshold_adaptive(warped, 251, offset = 10)\n",
    "#warped = warped.astype(\"uint8\") * 255\n",
    "\n",
    "# show the original and scanned images\n",
    "#print (\"STEP 3: Apply perspective transform\")\n",
    "#cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "#cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "#cv2.waitKey(0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
